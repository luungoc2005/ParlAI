python -m parlai.scripts.train_distill_model \
-t fromfile:parlaiformat --fromfile_datapath ./data/reddit/train.txt -dt train:stream \
-m transformer/generator_distilled \
-mf ./checkpoints/transformer-distilled-2 \
-teacher-model-file zoo:blender/blender_90M/model \
--dict-lower True \
--variant prelayernorm --n_positions=512 --truncate=512 \
--inference greedy --beam-size 1 --skip-generation True \
--share_word_embeddings True \
--embedding-size 768 --n-heads 8 --n-layers 12 --ffn_size 768 --activation gelu --gradient-clip 0.1 \
--learn-positional-embeddings True --dropout 0.1 --attention-dropout 0.1 \
--num-epochs 1 -veps 0.01 -vme 512 -vmt ppl -vmm min -sval True \
-bs 16 --optimizer adamax -lr 1e-05 \
--warmup_updates -1 --warmup_rate 0.0001 -vp 500 \
-tblog True --fp16 True --fp16-impl apex --evaltask convai2
